{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random as rand\n",
    "\n",
    "data = pd.read_csv(\"titanic_data.csv\")\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6215ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1\n",
    "df.describe()\n",
    "\n",
    "# Passengers in Class 1 and 2 have value 1, and Passengers in Class 3 have value 0\n",
    "# Passengers in first and second class have higher status, and are more likely to survive\n",
    "df['Pclass'] = np.where(df['Pclass'] < 3, 1, 0)\n",
    "\n",
    "# Passengers no more than 28 years old have value 1, and older Passengers value 0\n",
    "# Younger Passengers tend to be more likely to survive because of physical strength and health\n",
    "# Choose 28 as the median of all ages\n",
    "df['Age'] = np.where(df['Age'] <= 28, 1, 0)\n",
    "\n",
    "# Single passengers have value 0, while passengers with any other relatives have value 0\n",
    "# Being single or being with family is critical to survival, but increase in family members would not matter much\n",
    "df['Siblings/Spouses Aboard'] = np.where(df['Siblings/Spouses Aboard'] == 0, 1, 0)\n",
    "df['Parents/Children Aboard'] = np.where(df['Parents/Children Aboard'] == 0, 1, 0)\n",
    "\n",
    "# Passengers with fare greater than $14.45 have value 1, and others have value 0\n",
    "# The ability to purchase a higher fare is directly related to higher status and survival rate\n",
    "df['Fare'] = np.where(df['Fare'] >= 14.45, 1, 0)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4b4c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.iloc[:,1:])\n",
    "y = np.array(df.iloc[:,0])\n",
    "np.count_nonzero(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ffe24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 (Compute Mutual Information)\n",
    "def entropy(X, index):\n",
    "    \"\"\"\n",
    "    In: \n",
    "    X: feature vector\n",
    "    index: index of a feature \n",
    "    \n",
    "    Out:\n",
    "    H(x): entropy of a feature x\n",
    "    \"\"\"\n",
    "\n",
    "    # Variable to return entropy\n",
    "    entropy = 0\n",
    "    values = [0, 1]\n",
    "    for value in values:\n",
    "        px = np.size(np.where(X[:, index] == value)) / len(X)\n",
    "        entropy -= px * math.log2(px) \n",
    "    return entropy\n",
    "\n",
    "def entropy_y(y):\n",
    "    \"\"\"\n",
    "    In: \n",
    "    y: response vector\n",
    "    index: index of a feature \n",
    "    \n",
    "    Out:\n",
    "    H(x): entropy of a feature x\n",
    "    \"\"\"\n",
    "\n",
    "    # Variable to return entropy\n",
    "    entropy = 0\n",
    "    \n",
    "    # Get uniques values of feature x, which are 0 and 1\n",
    "    values = [0, 1]\n",
    "\n",
    "    for value in values:\n",
    "        py = np.size(np.where(y == value)) / len(y)\n",
    "        entropy -= py * math.log2(py) \n",
    "    return entropy\n",
    "    \n",
    "def conditional_entropy(X, index, y):\n",
    "    \"\"\"\n",
    "    In: \n",
    "    X: feature vector\n",
    "    index: index of a feature \n",
    "    y: response vector\n",
    "    \n",
    "    Out:\n",
    "    H(x, y): conditional entropy of sample x with respect to y\n",
    "    \"\"\"\n",
    "    \n",
    "    conditional_entropy = 0\n",
    "    # Get uniques values of feature x and response y, which are both 0 and 1\n",
    "    values_x = set(X[:, index])\n",
    "    values_y = set(Y)\n",
    "    \n",
    "    for value_x in values_x:\n",
    "        for value_y in values_y:\n",
    "            # Compute the cross entropy between x and y\n",
    "            pxy = len(np.where(np.in1d(np.where(X[:, index]==value_x), \n",
    "                            np.where(y==value_y))==True)) / len(X)\n",
    "            \n",
    "            # Calculate the conditional entropy from single and cross entropy\n",
    "            conditional_entropy -= pxy * math.log2(pxy/(entropy(X, index)*entropy_y(y)))\n",
    "    return conditional_entropy\n",
    "\n",
    "\n",
    "def mutual_information(X, index, y):\n",
    "    \"\"\"\n",
    "    In: \n",
    "    X: feature vector\n",
    "    index: index of a feature \n",
    "    y: response vector\n",
    "    \n",
    "    Out:\n",
    "    I(x, y): mutual information of sample x\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate entropy and conditional entropy\n",
    "    H_x = entropy(X, index)\n",
    "    H_xy = conditional_entropy(X, index, y)\n",
    "\n",
    "    # Calculate Mutual Information\n",
    "    I_xy = H_x - H_xy\n",
    "    return  I_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00acf03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 (Build a Decision Tree)\n",
    "def split(X,index):\n",
    "    \"\"\"\n",
    "    In: \n",
    "    X: feature vector\n",
    "    index: index of the feature to split data on\n",
    "    \n",
    "    Out:\n",
    "    set 0, set 1: two data sets based on the value of X[index]\n",
    "    \"\"\"\n",
    "    split_function = lambda X:X[index] == 0\n",
    "    set0 = [x for x in X if split_function(x)]\n",
    "    set1 = [x for x in X if not split_function(x)]\n",
    "    return(set0, set1)\n",
    "\n",
    "class node:\n",
    "    def __init__(self, feature = None, leftnode = None, rightnode = None, end = False, result = None):\n",
    "        self.feature = feature\n",
    "        self.leftnode = leftnode\n",
    "        self.rightnode = rightnode\n",
    "        self.end = False\n",
    "        self.result = None\n",
    "\n",
    "class tree:\n",
    "    def __init__(self, X=None, y=None):\n",
    "        self.root = None\n",
    "        self.decisiontree(X,y)\n",
    "\n",
    "    def decisiontree(self, X, y):\n",
    "        self.root = self.build_node(X,y,np.arange(len(X[0])))\n",
    "        self.graph = None\n",
    "\n",
    "    def build_node(self, X, y, indices):\n",
    "        # Create a node\n",
    "        n = node()\n",
    "        \n",
    "        # Stopping Conditions:\n",
    "        # 1: entropy of y is close to zero\n",
    "        # 2: the sample size is smaller than 5% of the total data\n",
    "        # 3: there are no more features left\n",
    "        \n",
    "        if entropy_y(y)<1e-5 or len(X)/887 < 0.05 or len(indices)==0:\n",
    "            node.end = True # It is a leaf \n",
    "            node.result = int(np.mean(y) > 0.5) # Check if there are more 0s or 1s\n",
    "        else:   \n",
    "            node.end=False # It is not a leaf\n",
    "\n",
    "            list_info = [mutual_information(X, index, y) for index in indices]\n",
    "            feature_index = list_info.index(np.amax(list_info)) # Find the index of feature with maximum MI\n",
    "            node.feature = feature_index\n",
    "            \n",
    "            X0, X1 = split(X, feature_index) # Split the data\n",
    "            y0 = y[np.where(X[:,indices[feature_index]] == 0)[0]]\n",
    "            y1 = y[np.where(X[:,indices[feature_index]] == 1)[0]]\n",
    "            new_indices = np.delete(indices, feature_index) # Delete the current index of the feature\n",
    "            node.leftnode = self.build_node(X0, y0, new_indices) # Recursively build the left nodes\n",
    "            node.rightnode = self.build_node(X1, y1, new_indices) # Recursively build the right nodes\n",
    "        return node\n",
    "    \n",
    "    def check(self,node,x):\n",
    "        if node.isend:\n",
    "              return node.result # Return value of the leaf: 0 or 1\n",
    "        if x[node.feature] == 0 :\n",
    "            return self.check(node.leftnode,x) # Recursively check leftnodes\n",
    "        else:\n",
    "            return self.check(node.rightnode,x) # Recursivley check rightnodes\n",
    "    \n",
    "    def classify(self,x):\n",
    "        if np.ndim(x)== 1:\n",
    "            return self.check(self.root,x)\n",
    "        if np.ndim(x)== 2:\n",
    "            y = np.zeros(len(X[0]))\n",
    "            for i in range(len(X[0])):\n",
    "                y[i]=self.check(self.root, x[i])\n",
    "        return y\n",
    "\n",
    "    def graph(tree,indent = ''):\n",
    "        if tree.results!=None:\n",
    "            print str(tree.results)\n",
    "        print indent + \"0: \",\n",
    "        graph(tree.leftnode,indent+\" \") # Recursion\n",
    "        print indent + \"1: \",\n",
    "        graph(tree.rightnode,indent+\" \") # Recursion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a26b7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4 \n",
    "t = tree(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa14457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5 (10-fold cross validation)\n",
    "\n",
    "def cv(X, folds):\n",
    "    X_split = []\n",
    "    fold_size = len(X[0]) // folds # Calculate the fold size\n",
    "\n",
    "    for i in range(folds):\n",
    "        fold = []\n",
    "        while len(fold) < fold_size:\n",
    "            j = rand.randrange(len(X[0])) # Choose a random element\n",
    "            index = X.index[j] # Find the index\n",
    "            fold.append(X[index])\n",
    "            X = X.drop(index) # Drop the data with the index\n",
    "        X_split.append(fold) # Concatenate subgroups of data\n",
    "    return X_split \n",
    "\n",
    "def kfold(X, y, k=10):\n",
    "    Xy = np.concatenate((X,y), axis = 0)\n",
    "    total = cv(Xy,k)\n",
    "    accuracy = []\n",
    "\n",
    "    for i in range(k):\n",
    "        k_list = np.arange(k)\n",
    "        k_list = np.delete(k_list, i)\n",
    "        for j in k_list :\n",
    "            if j == k_list[0]:\n",
    "                cv = total[j]\n",
    "            cv = np.concatenate((cv,total[j]), axis=0) \n",
    "            \n",
    "        t = tree(X,y)\n",
    "        test = t.classify(cv)\n",
    "        a = np.sum(test == Xy[-1])\n",
    "        \n",
    "        acc = a/len(test) # Calculate accuracy of each prediction\n",
    "        result.append(a/len(test))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748af4ba",
   "metadata": {},
   "source": [
    "### Q5\n",
    "\n",
    "The accuracy is about 80%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb186d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6\n",
    "x = np.array([3, 1, 30, 0, 0, 100])\n",
    "t = tree(X, y)\n",
    "t.classify(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668b21a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7 (Random Forests)\n",
    "\n",
    "# Choose a subsample of 20% of total data\n",
    "def subset(X, ratio=0.2):\n",
    "    subset = list()\n",
    "    n = int(len(X) * ratio)\n",
    "    while len(subset) < n:\n",
    "        index = rand.randrange(len(X))\n",
    "        subset.append(X[index])\n",
    "    return subset\n",
    "\n",
    "# Use consensus to decide the prediction\n",
    "def predict(trees, x):\n",
    "    for tree in trees:\n",
    "        predictions = [tree.classify(x)]\n",
    "    return max(set(predictions)) \n",
    "\n",
    "def random_forest(training, testing, y, n_trees = 5):\n",
    "    trees = list()\n",
    "    for i in range(n_trees):\n",
    "        sample = subset(training)\n",
    "        t = tree(training, y)\n",
    "        trees.append(t)\n",
    "    predictions = [predict(trees, x) for x in testing]\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d940a4c4",
   "metadata": {},
   "source": [
    "### Q9\n",
    "All the predictions have shown that, with the choice of $x$, I would have survived the Titanic. I would prefer to use Logistic Regression because the impaired robustness of our implementation of Random Forest, since we only have all binary variables instead of categorical variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4253aefa",
   "metadata": {},
   "source": [
    "### Q10\n",
    "\n",
    "$H(x) = \\sum_{\\mathtt{x}\\in X}P(x=\\mathtt{x})\\log_2(\\frac{1}{P(x=\\mathtt{x})}) \n",
    "= \\sum_{\\mathtt{x}\\in X}\\sum_{\\mathtt{y}\\in Y}P(x=\\mathtt{x}, y=\\mathtt{y})\\log_2(\\frac{1}{P(x=\\mathtt{x})})$\n",
    "\n",
    "$H(x|y) = \\sum_{\\mathtt{x}\\in X}\\sum_{\\mathtt{y}\\in Y}P(x=\\mathtt{x}, y=\\mathtt{y})\\log_2(\\frac{1}{P(x=\\mathtt{x}|y=\\mathtt{y})})$\n",
    "\n",
    "$I(x;y) = H(x)-H(x|y) = \\sum_{\\mathtt{x}\\in X}\\sum_{\\mathtt{y}\\in Y}P(x=\\mathtt{x}, y=\\mathtt{y})\\log_2(\\frac{P(x=\\mathtt{x}|y=\\mathtt{y})}{P(x=\\mathtt{x})}) = \n",
    "\\sum_{\\mathtt{x}\\in X}\\sum_{\\mathtt{y}\\in Y}P(x=\\mathtt{x}, y=\\mathtt{y})\\log_2(\\frac{P(x=\\mathtt{x}, y=\\mathtt{y})}{P(x=\\mathtt{x})P(y=\\mathtt{y})})\n",
    "$\n",
    "\n",
    "$H(y) = \\sum_{\\mathtt{y}\\in Y}P(y=\\mathtt{y})\\log_2(\\frac{1}{P(y=\\mathtt{y})}) \n",
    "= \\sum_{\\mathtt{y}\\in Y}\\sum_{\\mathtt{x}\\in X}P(y=\\mathtt{y}, x=\\mathtt{x})\\log_2(\\frac{1}{P(y=\\mathtt{y})})$\n",
    "\n",
    "$H(y|x) = \\sum_{\\mathtt{y}\\in Y}\\sum_{\\mathtt{x}\\in X}P(y=\\mathtt{y}, x=\\mathtt{x})\\log_2(\\frac{1}{P(y=\\mathtt{y}|x=\\mathtt{x})})$\n",
    "\n",
    "$I(y;x) = H(y)-H(y|x) = \\sum_{\\mathtt{y}\\in Y}\\sum_{\\mathtt{x}\\in X}P(y=\\mathtt{y}, x=\\mathtt{x})\\log_2(\\frac{P(y=\\mathtt{y}|x=\\mathtt{x})}{P(y=\\mathtt{y})}) = \n",
    "\\sum_{\\mathtt{y}\\in Y}\\sum_{\\mathtt{x}\\in X}P(y=\\mathtt{y}, x=\\mathtt{x})\\log_2(\\frac{P(y=\\mathtt{y}, x=\\mathtt{y})}{P(y=\\mathtt{y})P(x=\\mathtt{x})})\n",
    "$\n",
    "\n",
    "Therefore, $I(x;y) = I(y;x)$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
